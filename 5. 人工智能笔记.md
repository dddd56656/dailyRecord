# 1. 题目记忆

你是谷歌cto,能否帮我一个一个提问下面的这些问题?在我回答完一个之后，单独进行解析?要求符合谷歌标准格式。要求在此聊天中一直保持。

你是谷歌cto，帮我进行批改，找到不对的地方，要求符合谷歌标准



ds,dify,mcp,fastgpt, 

# 2. 机器学习与深度学习理论基础

## 2.1   机器学习分类: 监督，半监督，无监督

![image-20251011160923060](5. 人工智能笔记.assets/image-20251011160923060.png)

![image-20251011164601627](5. 人工智能笔记.assets/image-20251011164601627.png)

###### 简单来说，监督学习就是根据房子的地段，位置这些已知的标签来预测价格。无监督学习就是不知道有哪些标签，但是根据相似度进行分类。半监督学习就是在分类的基础上进行标签标记。

![image-20251011164230381](5. 人工智能笔记.assets/image-20251011164230381.png)

单变量线性回归



![image-20251011172037044](5. 人工智能笔记.assets/image-20251011172037044.png)

![image-20251011172129216](5. 人工智能笔记.assets/image-20251011172129216.png)





![image-20251011173627292](5. 人工智能笔记.assets/image-20251011173627292.png)



###### 简单来说，就是针对新系数的函数，但是得到系统的自变量的方式是通过损失函数进行求导得到系数的自变量，最后直到误差达到最小值，再往下走就会变大，来进行停止。

```txt
✅ **是的！你理解得已经非常接近核心本质了。下面我来帮你把这句话再“精炼+结构化”一下，形成一个彻底清晰的理解：**

---

## ✅ 简单来说（结构化表述）：

1. **我们想训练的是一个“预测函数”**：
   [
   \hat{y} = h_\theta(x) = \theta_0 + \theta_1 x
   ]

   * 系数 ( \theta ) 是这个函数的“控制参数”

---

2. **损失函数 J(θ)** 用来衡量：
   👉 当前这组系数（θ）到底预测得准不准

---

3. **我们不知道最佳 θ 是多少，所以设计了一个“系统函数” J(θ)**
   👉 J(θ) 是关于 θ 的函数，它的“最小值点”就是我们要找的最优参数

---

4. **怎么找到最小点？**
   👉 通过对 J(θ) 对 θ 求导
   👉 导数告诉我们“J(θ)往哪里减小最快”（即“下坡方向”）

---

5. **梯度下降做的事情就是：**
   [
   \theta := \theta - \alpha \cdot \frac{\partial J(\theta)}{\partial \theta}
   ]
   👉 沿着导数方向不断调整 θ，让 J(θ) 越来越小

---

6. **直到有一天：导数 ≈ 0，或者 J(θ) 不再明显下降 ⇒ 达到最小值 ⇒ 停止**

   * 此时的 θ，就是**你模型的最终参数**
   * 它能让模型预测误差最小 ✅

---

## ✅ 最终一句话总结你这句话的本质意思：

> 我们通过对损失函数 J(θ) 对 θ 求导，找出“调整系数的最佳方向”，一步步靠近误差最小点，直到再调整就会让误差变大 ⇒ 停止 ⇒ 得到最优系数。

---

你已经很接近工程师/研究员级别的理解了。

是否想要我用图像（例如 J(θ) 的 U 形曲线 + θ 下降轨迹）来再加强这个直觉？你说一句“上图”就搞。

```

![image-20251011172220528](5. 人工智能笔记.assets/image-20251011172220528.png)

###### 缩放是为了在多变量问题中，防止某个特征因为数值过大而主导模型训练，导致梯度失衡、收敛困难。

###### 非监督学习，份K-mean聚类和PCA降维

![image-20251011235408568](5. 人工智能笔记.assets/image-20251011235408568.png)

![image-20251011235706633](5. 人工智能笔记.assets/image-20251011235706633.png)

![image-20251011235456555](5. 人工智能笔记.assets/image-20251011235456555.png)

![image-20251011235724073](5. 人工智能笔记.assets/image-20251011235724073.png)

![image-20251011235517048](5. 人工智能笔记.assets/image-20251011235517048.png)

![image-20251011235534122](5. 人工智能笔记.assets/image-20251011235534122.png)

![image-20251011235557478](5. 人工智能笔记.assets/image-20251011235557478.png)



###### 半监督学习，简单来说，通过少量标注进行模型训练的算法，例如Self-Learning+Noisy-Student

![image-20251011235816049](5. 人工智能笔记.assets/image-20251011235816049.png)

![image-20251012000546168](5. 人工智能笔记.assets/image-20251012000546168.png)

![image-20251012000438978](5. 人工智能笔记.assets/image-20251012000438978.png)

![image-20251012000450851](5. 人工智能笔记.assets/image-20251012000450851.png)

![image-20251012000503580](5. 人工智能笔记.assets/image-20251012000503580.png)



###### 神经网络，简单来说，就是输入 经过单个或者多个函数 输出，激活函数则是条件限制

![image-20251012193854377](5. 人工智能笔记.assets/image-20251012193854377.png)



![image-20251012193924734](5. 人工智能笔记.assets/image-20251012193924734.png)





![image-20251012193953029](5. 人工智能笔记.assets/image-20251012193953029.png)



![image-20251012194006026](5. 人工智能笔记.assets/image-20251012194006026.png)

###### 简单来说，全连接就是上一层所有神经元和下一层所有神经元都可以互相连接

![image-20251012194447390](5. 人工智能笔记.assets/image-20251012194447390.png)

![image-20251012194605428](5. 人工智能笔记.assets/image-20251012194605428.png)

###### 前向传播（Forward Propagation）**：输入数据，层层计算，最后输出预测结果。反向传播（Backward Propagation）**：根据预测误差，借助优化器（如梯度下降）来更新参数（权重和偏置）

![image-20251012194710382](5. 人工智能笔记.assets/image-20251012194710382.png)

![image-20251012194941573](5. 人工智能笔记.assets/image-20251012194941573.png)

###### 前向传播得出结果，后向传播则是根据优化器得到新的系数

###### 

![image-20251012195003861](5. 人工智能笔记.assets/image-20251012195003861.png)

![image-20251012195022542](5. 人工智能笔记.assets/image-20251012195022542.png)

![image-20251012195042356](5. 人工智能笔记.assets/image-20251012195042356.png)

###### 深度学习，简单来说，输入，经过卷积层提取特征值，经过池化层压缩，到全连接层分类。卷积则是通过卷积核进行矩阵乘法宽度自然变小。

![image-20251012195606672](5. 人工智能笔记.assets/image-20251012195606672.png)

![image-20251012195733956](5. 人工智能笔记.assets/image-20251012195733956.png)

![image-20251012195749381](5. 人工智能笔记.assets/image-20251012195749381.png)



![image-20251012195807475](5. 人工智能笔记.assets/image-20251012195807475.png)

![image-20251012195821983](5. 人工智能笔记.assets/image-20251012195821983.png)







![image-20251012195841739](5. 人工智能笔记.assets/image-20251012195841739.png)

![image-20251012195942490](5. 人工智能笔记.assets/image-20251012195942490.png)

![image-20251012200006835](5. 人工智能笔记.assets/image-20251012200006835.png)

![image-20251012200024999](5. 人工智能笔记.assets/image-20251012200024999.png)

![](5. 人工智能笔记.assets/image-20251012200219054.png)



![image-20251012200554717](5. 人工智能笔记.assets/image-20251012200554717.png)



![image-20251012200237593](5. 人工智能笔记.assets/image-20251012200237593.png)





![image-20251012200249325](5. 人工智能笔记.assets/image-20251012200249325.png)

![image-20251012200311666](5. 人工智能笔记.assets/image-20251012200311666.png)

![image-20251012200331116](5. 人工智能笔记.assets/image-20251012200331116.png)



![image-20251012200342323](5. 人工智能笔记.assets/image-20251012200342323.png)



![image-20251012200358187](5. 人工智能笔记.assets/image-20251012200358187.png)



![image-20251012200415283](5. 人工智能笔记.assets/image-20251012200415283.png)



![image-20251012200441986](5. 人工智能笔记.assets/image-20251012200441986.png)





# 3：大模型发展全景与关键技术





















